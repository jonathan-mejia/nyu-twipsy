{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines Exploration\n",
    "\n",
    "The purpose of a pipeline is to seamlessly fix various problems in the machine learning process\n",
    "\n",
    "* Data might not be in $R^d$\n",
    "* Features need to be engineered\n",
    "* Transformations need to be applied\n",
    "* Hyperparameters need to be tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dao import DataAccess\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we easily instantiate a `DataAccess` and get the data in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = DataAccess.as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>labels</th>\n",
       "      <th>predict</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>556e0ee3d6dfbb462880f0a5</th>\n",
       "      <td>Tue Jun 02 20:16:08 +0000 2015</td>\n",
       "      <td>{'alcohol': 0}</td>\n",
       "      <td>0.526050</td>\n",
       "      <td>Impatiently waiting to get our hands on the ne...</td>\n",
       "      <td>{'friends_count': 1997, 'created_at': 'Thu Jun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556e128ad6dfbb46288111e4</th>\n",
       "      <td>Tue Jun 02 20:31:44 +0000 2015</td>\n",
       "      <td>{'alcohol': 1}</td>\n",
       "      <td>0.516649</td>\n",
       "      <td>Beer fans need their @ColumbusBrewing Bodhi. I...</td>\n",
       "      <td>{'friends_count': 960, 'created_at': 'Mon Oct ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              created_at          labels  \\\n",
       "_id                                                                        \n",
       "556e0ee3d6dfbb462880f0a5  Tue Jun 02 20:16:08 +0000 2015  {'alcohol': 0}   \n",
       "556e128ad6dfbb46288111e4  Tue Jun 02 20:31:44 +0000 2015  {'alcohol': 1}   \n",
       "\n",
       "                           predict  \\\n",
       "_id                                  \n",
       "556e0ee3d6dfbb462880f0a5  0.526050   \n",
       "556e128ad6dfbb46288111e4  0.516649   \n",
       "\n",
       "                                                                       text  \\\n",
       "_id                                                                           \n",
       "556e0ee3d6dfbb462880f0a5  Impatiently waiting to get our hands on the ne...   \n",
       "556e128ad6dfbb46288111e4  Beer fans need their @ColumbusBrewing Bodhi. I...   \n",
       "\n",
       "                                                                       user  \n",
       "_id                                                                          \n",
       "556e0ee3d6dfbb462880f0a5  {'friends_count': 1997, 'created_at': 'Thu Jun...  \n",
       "556e128ad6dfbb46288111e4  {'friends_count': 960, 'created_at': 'Mon Oct ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ItemGetter(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This canonical ItemGetter is a Transformer for Pipeline objects.\n",
    "    Initialize the ItemGetter with a `key` and its transform call will select a column out\n",
    "    of the specified column.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.key]\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return X[self.key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Pipeline\n",
    "\n",
    "First on our list is a simple Text Pipeline that uses TfidfVectorizer and TruncatedSVD (LSI)\n",
    "Also use Twokenize from [brendano/tweetmotif](https://github.com/brendano/tweetmotif).\n",
    "\n",
    "    Brendan O'Connor, Michel Krieger, and David Ahn. TweetMotif: Exploratory Search and Topic Summarization for Twitter. ICWSM-2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from twokenize import tokenize\n",
    "\n",
    "text_pipe = []\n",
    "\n",
    "text_pipe.append(\n",
    "    (\"text\", \n",
    "     ItemGetter(\"text\")\n",
    "    )\n",
    ")\n",
    "\n",
    "text_pipe.append(\n",
    "    (\"tfidf\", \n",
    "     TfidfVectorizer(\n",
    "            analyzer=\"char\",\n",
    "            ngram_range=(2,5),\n",
    "            min_df = 10,\n",
    "            max_df = .98\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "text_pipe.append(\n",
    "    (\"lsi\",\n",
    "    TruncatedSVD(\n",
    "            n_components=3000\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# TruncatedSVD is annoying expensive...\n",
    "text_pipeline = Pipeline(text_pipe[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Work: \n",
    "\n",
    "Incorperate Gensim Phrases, and LDA as custom transformers with the ability to load them from files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Pipeline\n",
    "\n",
    "### Vectorizers\n",
    "\n",
    "I'll describe vectorization process a bit later as i've design it in a way so that it can be easily modified\n",
    "for future implementations.\n",
    "\n",
    "### Transformers\n",
    "\n",
    "`DateTimeTransformer` takes the `created_at` selection and converts it into a `pandas.DatetimeIndex` which is amazingly powerful.\n",
    "\n",
    "Currently I am using the `dayofweek`, `hour`, and `hourofweek` features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class DateTimeTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return pd.DatetimeIndex(X)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "class DatetimeIndex(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    allowed_kinds = {\"dayofweek\", \"hour\", \"hourofweek\"}\n",
    "    \n",
    "    def __init__(self, kind):\n",
    "        self.kind = kind\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        n = len(X)\n",
    "        if self.kind == \"hourofweek\":\n",
    "            col = X.dayofweek * 24 + X.hour\n",
    "        else:\n",
    "            col = getattr(X, self.kind)\n",
    "        return pd.DataFrame(col)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "time_pipe = list()\n",
    "\n",
    "time_pipe.append(\n",
    "    (\"get_created_at\", \n",
    "     ItemGetter(\"created_at\")\n",
    "    )\n",
    ")\n",
    "\n",
    "time_pipe.append(\n",
    "    (\"to_datetimeindex\",\n",
    "    DateTimeTransformer()\n",
    "    )\n",
    ")\n",
    "\n",
    "time_pipe.append(\n",
    "    (\"features\",\n",
    "    FeatureUnion([\n",
    "        (\"dayofweek\", \n",
    "         Pipeline(\n",
    "                    [(\"index\", DatetimeIndex(\"dayofweek\")),\n",
    "                     (\"onehot\", OneHotEncoder())])),\n",
    "        (\"hour\", \n",
    "         Pipeline(\n",
    "                    [(\"index\", DatetimeIndex(\"hour\")),\n",
    "                     (\"onehot\", OneHotEncoder())])),\n",
    "        (\"hourofweek\", \n",
    "         Pipeline(\n",
    "                    [(\"index\", DatetimeIndex(\"hourofweek\")),\n",
    "                     (\"onehot\", OneHotEncoder())]))\n",
    "        ])\n",
    "    )\n",
    ")\n",
    "\n",
    "tp = Pipeline(time_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Work\n",
    "\n",
    "Notice that right now the things are all OneHotEncoded. This will change later. We see that a lot of this infromation is periodic so we can probably include features like the different between Phases rather than the time itself.\n",
    "\n",
    "This will probably function better than collapsing it into larger semantic intervals like `Afternoon` or `Sunday Afternoon`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Pipeline\n",
    "\n",
    "From prior exploration it seems that log scaling them helps a lot. Noreover, a feature called normality also helps greatly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On read, There user column is a dict so we need a transformer to convert it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Dict2DF(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return pd.DataFrame.from_records(X, index=X.index)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u = Dict2DF().fit_transform(X.user).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>statuses_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>556e0ee3d6dfbb462880f0a5</th>\n",
       "      <td>Thu Jun 12 22:14:05 +0000 2014</td>\n",
       "      <td>394</td>\n",
       "      <td>407</td>\n",
       "      <td>1997</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556e128ad6dfbb46288111e4</th>\n",
       "      <td>Mon Oct 06 21:00:38 +0000 2008</td>\n",
       "      <td>806</td>\n",
       "      <td>1006</td>\n",
       "      <td>960</td>\n",
       "      <td>10442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556e1464d6dfbb4628812330</th>\n",
       "      <td>Sun Mar 11 08:22:56 +0000 2012</td>\n",
       "      <td>860</td>\n",
       "      <td>703</td>\n",
       "      <td>684</td>\n",
       "      <td>89573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556e15f1d6dfbb4628813236</th>\n",
       "      <td>Thu Jan 14 03:03:33 +0000 2010</td>\n",
       "      <td>3473</td>\n",
       "      <td>9414</td>\n",
       "      <td>1486</td>\n",
       "      <td>16435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556e1adcd6dfbb50e34a1ed6</th>\n",
       "      <td>Sun Oct 24 23:02:03 +0000 2010</td>\n",
       "      <td>3964</td>\n",
       "      <td>519</td>\n",
       "      <td>434</td>\n",
       "      <td>32154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              created_at  favourites_count  \\\n",
       "_id                                                                          \n",
       "556e0ee3d6dfbb462880f0a5  Thu Jun 12 22:14:05 +0000 2014               394   \n",
       "556e128ad6dfbb46288111e4  Mon Oct 06 21:00:38 +0000 2008               806   \n",
       "556e1464d6dfbb4628812330  Sun Mar 11 08:22:56 +0000 2012               860   \n",
       "556e15f1d6dfbb4628813236  Thu Jan 14 03:03:33 +0000 2010              3473   \n",
       "556e1adcd6dfbb50e34a1ed6  Sun Oct 24 23:02:03 +0000 2010              3964   \n",
       "\n",
       "                          followers_count  friends_count  statuses_count  \n",
       "_id                                                                       \n",
       "556e0ee3d6dfbb462880f0a5              407           1997             823  \n",
       "556e128ad6dfbb46288111e4             1006            960           10442  \n",
       "556e1464d6dfbb4628812330              703            684           89573  \n",
       "556e15f1d6dfbb4628813236             9414           1486           16435  \n",
       "556e1adcd6dfbb50e34a1ed6              519            434           32154  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UserEgoVectorizer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X[\"normality\"] = u.friends_count / (u.followers_count + u.friends_count + 1)\n",
    "        u.favourites_count = np.log(u.favourites_count)\n",
    "        u.followers_count = np.log(u.followers_count)\n",
    "        u.statuses_count = np.log(u.statuses_count)\n",
    "        u.favourites_count = np.log(u.favourites_count)\n",
    "        return pd.DataFrame.from_records(X)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
