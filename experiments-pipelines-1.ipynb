{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines Exploration\n",
    "\n",
    "The purpose of a pipeline is to seamlessly fix various problems in the machine learning process\n",
    "\n",
    "* Data might not be in $R^d$\n",
    "* Features need to be engineered\n",
    "* Transformations need to be applied\n",
    "* Hyperparameters need to be tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dao import DataAccess\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we easily instantiate a `DataAccess` and get the data in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = DataAccess.as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>labels</th>\n",
       "      <th>predict</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>556e0ee3d6dfbb462880f0a5</th>\n",
       "      <td>Tue Jun 02 20:16:08 +0000 2015</td>\n",
       "      <td>{'alcohol': 0}</td>\n",
       "      <td>0.526050</td>\n",
       "      <td>Impatiently waiting to get our hands on the ne...</td>\n",
       "      <td>{'created_at': 'Thu Jun 12 22:14:05 +0000 2014...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556e128ad6dfbb46288111e4</th>\n",
       "      <td>Tue Jun 02 20:31:44 +0000 2015</td>\n",
       "      <td>{'alcohol': 1}</td>\n",
       "      <td>0.516649</td>\n",
       "      <td>Beer fans need their @ColumbusBrewing Bodhi. I...</td>\n",
       "      <td>{'created_at': 'Mon Oct 06 21:00:38 +0000 2008...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              created_at          labels  \\\n",
       "_id                                                                        \n",
       "556e0ee3d6dfbb462880f0a5  Tue Jun 02 20:16:08 +0000 2015  {'alcohol': 0}   \n",
       "556e128ad6dfbb46288111e4  Tue Jun 02 20:31:44 +0000 2015  {'alcohol': 1}   \n",
       "\n",
       "                           predict  \\\n",
       "_id                                  \n",
       "556e0ee3d6dfbb462880f0a5  0.526050   \n",
       "556e128ad6dfbb46288111e4  0.516649   \n",
       "\n",
       "                                                                       text  \\\n",
       "_id                                                                           \n",
       "556e0ee3d6dfbb462880f0a5  Impatiently waiting to get our hands on the ne...   \n",
       "556e128ad6dfbb46288111e4  Beer fans need their @ColumbusBrewing Bodhi. I...   \n",
       "\n",
       "                                                                       user  \n",
       "_id                                                                          \n",
       "556e0ee3d6dfbb462880f0a5  {'created_at': 'Thu Jun 12 22:14:05 +0000 2014...  \n",
       "556e128ad6dfbb46288111e4  {'created_at': 'Mon Oct 06 21:00:38 +0000 2008...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers and Utilities\n",
    "\n",
    "    class ExploringRecordJoiner()\n",
    "    class ItemGetter()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding Nested Dictionary Columns\n",
    "\n",
    "We use `ExplodingRecordJoiner` to fix the problem we see with this user column. Notice that its a dictionary..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id\n",
       "556e0ee3d6dfbb462880f0a5    {'created_at': 'Thu Jun 12 22:14:05 +0000 2014...\n",
       "556e128ad6dfbb46288111e4    {'created_at': 'Mon Oct 06 21:00:38 +0000 2008...\n",
       "556e1464d6dfbb4628812330    {'created_at': 'Sun Mar 11 08:22:56 +0000 2012...\n",
       "556e15f1d6dfbb4628813236    {'created_at': 'Thu Jan 14 03:03:33 +0000 2010...\n",
       "556e1adcd6dfbb50e34a1ed6    {'created_at': 'Sun Oct 24 23:02:03 +0000 2010...\n",
       "Name: user, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ExplodingRecordJoiner(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    ExplodingRecordJoiner\n",
    "    ~~~~~~~~~~~~~~~~~~~~~\n",
    "    \n",
    "    ExplodingRecordJoiner is a Transformer for Pipeline Objects\n",
    "    \n",
    "    Usage:\n",
    "        The reason we use this is because of the fact that\n",
    "        using DataFrams is better than using JSON parsing.\n",
    "    \n",
    "        However, the data coming in is nested JSON so this exploder \n",
    "        allows use to select a `col` that is one level nested dictionary\n",
    "        (taken from json) and selects the `subcol` and joins\n",
    "        it to the original DataFrame.\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        self.cols = kwargs\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Extract column of dicts then apply from_records,\n",
    "        # Match indicies then select the `subcols` we want,\n",
    "        # Join with existing DataFrame.\n",
    "        for col, subcol in self.cols.items():\n",
    "            new_cols = [\"{}.{}\".format(col, c) for c in subcol]\n",
    "            sub = pd.DataFrame.from_records(X[col], index=X.index)[subcol]\n",
    "            sub.columns = new_cols\n",
    "            X = X.join(sub)\n",
    "        return X\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        st = [k+\"=\"+ str(v) for k,v in self.cols.items()]\n",
    "        return \"ExplodingRecordJoiner({})\".format(\", \".join(st))\n",
    "    \n",
    "    def get_params(self):\n",
    "        return self.cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of a ExplodingRecordJoiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>labels</th>\n",
       "      <th>predict</th>\n",
       "      <th>text</th>\n",
       "      <th>user</th>\n",
       "      <th>user.created_at</th>\n",
       "      <th>user.favourites_count</th>\n",
       "      <th>user.followers_count</th>\n",
       "      <th>user.friends_count</th>\n",
       "      <th>user.statuses_count</th>\n",
       "      <th>user.verified</th>\n",
       "      <th>labels.alcohol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>556e0ee3d6dfbb462880f0a5</th>\n",
       "      <td>Tue Jun 02 20:16:08 +0000 2015</td>\n",
       "      <td>{'alcohol': 0}</td>\n",
       "      <td>0.526050</td>\n",
       "      <td>Impatiently waiting to get our hands on the ne...</td>\n",
       "      <td>{'created_at': 'Thu Jun 12 22:14:05 +0000 2014...</td>\n",
       "      <td>Thu Jun 12 22:14:05 +0000 2014</td>\n",
       "      <td>394</td>\n",
       "      <td>407</td>\n",
       "      <td>1997</td>\n",
       "      <td>823</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556e128ad6dfbb46288111e4</th>\n",
       "      <td>Tue Jun 02 20:31:44 +0000 2015</td>\n",
       "      <td>{'alcohol': 1}</td>\n",
       "      <td>0.516649</td>\n",
       "      <td>Beer fans need their @ColumbusBrewing Bodhi. I...</td>\n",
       "      <td>{'created_at': 'Mon Oct 06 21:00:38 +0000 2008...</td>\n",
       "      <td>Mon Oct 06 21:00:38 +0000 2008</td>\n",
       "      <td>806</td>\n",
       "      <td>1006</td>\n",
       "      <td>960</td>\n",
       "      <td>10442</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556e1464d6dfbb4628812330</th>\n",
       "      <td>Tue Jun 02 20:39:37 +0000 2015</td>\n",
       "      <td>{'alcohol': 1}</td>\n",
       "      <td>0.502633</td>\n",
       "      <td>Stone Cold use to be the baddest MF in my book...</td>\n",
       "      <td>{'created_at': 'Sun Mar 11 08:22:56 +0000 2012...</td>\n",
       "      <td>Sun Mar 11 08:22:56 +0000 2012</td>\n",
       "      <td>860</td>\n",
       "      <td>703</td>\n",
       "      <td>684</td>\n",
       "      <td>89573</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556e15f1d6dfbb4628813236</th>\n",
       "      <td>Tue Jun 02 20:46:14 +0000 2015</td>\n",
       "      <td>{'alcohol': 1}</td>\n",
       "      <td>0.535758</td>\n",
       "      <td>Now @iamjohnoliver has to drink a Bud Light Li...</td>\n",
       "      <td>{'created_at': 'Thu Jan 14 03:03:33 +0000 2010...</td>\n",
       "      <td>Thu Jan 14 03:03:33 +0000 2010</td>\n",
       "      <td>3473</td>\n",
       "      <td>9414</td>\n",
       "      <td>1486</td>\n",
       "      <td>16435</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              created_at          labels  \\\n",
       "_id                                                                        \n",
       "556e0ee3d6dfbb462880f0a5  Tue Jun 02 20:16:08 +0000 2015  {'alcohol': 0}   \n",
       "556e128ad6dfbb46288111e4  Tue Jun 02 20:31:44 +0000 2015  {'alcohol': 1}   \n",
       "556e1464d6dfbb4628812330  Tue Jun 02 20:39:37 +0000 2015  {'alcohol': 1}   \n",
       "556e15f1d6dfbb4628813236  Tue Jun 02 20:46:14 +0000 2015  {'alcohol': 1}   \n",
       "\n",
       "                           predict  \\\n",
       "_id                                  \n",
       "556e0ee3d6dfbb462880f0a5  0.526050   \n",
       "556e128ad6dfbb46288111e4  0.516649   \n",
       "556e1464d6dfbb4628812330  0.502633   \n",
       "556e15f1d6dfbb4628813236  0.535758   \n",
       "\n",
       "                                                                       text  \\\n",
       "_id                                                                           \n",
       "556e0ee3d6dfbb462880f0a5  Impatiently waiting to get our hands on the ne...   \n",
       "556e128ad6dfbb46288111e4  Beer fans need their @ColumbusBrewing Bodhi. I...   \n",
       "556e1464d6dfbb4628812330  Stone Cold use to be the baddest MF in my book...   \n",
       "556e15f1d6dfbb4628813236  Now @iamjohnoliver has to drink a Bud Light Li...   \n",
       "\n",
       "                                                                       user  \\\n",
       "_id                                                                           \n",
       "556e0ee3d6dfbb462880f0a5  {'created_at': 'Thu Jun 12 22:14:05 +0000 2014...   \n",
       "556e128ad6dfbb46288111e4  {'created_at': 'Mon Oct 06 21:00:38 +0000 2008...   \n",
       "556e1464d6dfbb4628812330  {'created_at': 'Sun Mar 11 08:22:56 +0000 2012...   \n",
       "556e15f1d6dfbb4628813236  {'created_at': 'Thu Jan 14 03:03:33 +0000 2010...   \n",
       "\n",
       "                                         user.created_at  \\\n",
       "_id                                                        \n",
       "556e0ee3d6dfbb462880f0a5  Thu Jun 12 22:14:05 +0000 2014   \n",
       "556e128ad6dfbb46288111e4  Mon Oct 06 21:00:38 +0000 2008   \n",
       "556e1464d6dfbb4628812330  Sun Mar 11 08:22:56 +0000 2012   \n",
       "556e15f1d6dfbb4628813236  Thu Jan 14 03:03:33 +0000 2010   \n",
       "\n",
       "                          user.favourites_count  user.followers_count  \\\n",
       "_id                                                                     \n",
       "556e0ee3d6dfbb462880f0a5                    394                   407   \n",
       "556e128ad6dfbb46288111e4                    806                  1006   \n",
       "556e1464d6dfbb4628812330                    860                   703   \n",
       "556e15f1d6dfbb4628813236                   3473                  9414   \n",
       "\n",
       "                          user.friends_count  user.statuses_count  \\\n",
       "_id                                                                 \n",
       "556e0ee3d6dfbb462880f0a5                1997                  823   \n",
       "556e128ad6dfbb46288111e4                 960                10442   \n",
       "556e1464d6dfbb4628812330                 684                89573   \n",
       "556e15f1d6dfbb4628813236                1486                16435   \n",
       "\n",
       "                         user.verified  labels.alcohol  \n",
       "_id                                                     \n",
       "556e0ee3d6dfbb462880f0a5         False               0  \n",
       "556e128ad6dfbb46288111e4         False               1  \n",
       "556e1464d6dfbb4628812330         False               1  \n",
       "556e15f1d6dfbb4628813236          True               1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ExplodingRecordJoiner(\n",
    "    labels=[\n",
    "        \"alcohol\"\n",
    "    ],\n",
    "    user=[\n",
    "        'created_at', \n",
    "        'favourites_count', \n",
    "        'followers_count', \n",
    "        'friends_count', \n",
    "        'statuses_count',\n",
    "        'verified'\n",
    "    ]\n",
    ").fit_transform(X).head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Text Column for Text Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ItemGetter(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    ItemGetter\n",
    "    ~~~~~~~~~~\n",
    "    \n",
    "    ItemGetter is a Transformer for Pipeline objects.\n",
    "    \n",
    "    Usage:\n",
    "        Initialize the ItemGetter with a `key` and its \n",
    "        transform call will select a column out of the \n",
    "        specified DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.key]\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of ItemGetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id\n",
       "556e0ee3d6dfbb462880f0a5    Impatiently waiting to get our hands on the ne...\n",
       "556e128ad6dfbb46288111e4    Beer fans need their @ColumbusBrewing Bodhi. I...\n",
       "556e1464d6dfbb4628812330    Stone Cold use to be the baddest MF in my book...\n",
       "556e15f1d6dfbb4628813236    Now @iamjohnoliver has to drink a Bud Light Li...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ItemGetter(\n",
    "    key=\"text\"\n",
    ").fit_transform(X).head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Features\n",
    "\n",
    "First on our list is a simple Text Pipeline that uses TfidfVectorizer and TruncatedSVD (LSI)\n",
    "Also use Twokenize from [brendano/tweetmotif](https://github.com/brendano/tweetmotif).\n",
    "\n",
    "    Brendan O'Connor, Michel Krieger, and David Ahn. TweetMotif: Exploratory Search and Topic Summarization for Twitter. ICWSM-2010.\n",
    "    \n",
    "Our basic pipeline is made up of TFIDF with LSI implemented by TruncatedSVD. Another Pipeline will be created using Gensim tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from twokenize import tokenize\n",
    "\n",
    "text_pipe = []\n",
    "\n",
    "text_pipe.append(\n",
    "    (\"text\", \n",
    "     ItemGetter(\"text\")\n",
    "    )\n",
    ")\n",
    "\n",
    "text_pipe.append(\n",
    "    (\"tfidf\", \n",
    "     TfidfVectorizer(\n",
    "            analyzer=\"char\",\n",
    "            ngram_range=(2,8),\n",
    "            min_df = 10,\n",
    "            max_df = .98\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "text_pipe.append(\n",
    "    (\"lsi\",\n",
    "    TruncatedSVD(\n",
    "            n_components=3000\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# TruncatedSVD is annoying expensive...\n",
    "text_pipeline = Pipeline(text_pipe[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Pipeline\n",
    "\n",
    "### Vectorizers\n",
    "\n",
    "I'll describe vectorization process a bit later as i've design it in a way so that it can be easily modified\n",
    "for future implementations.\n",
    "\n",
    "### Transformers\n",
    "\n",
    "`DateTimeTransformer` takes the `created_at` selection and converts it into a `pandas.DatetimeIndex` which is amazingly powerful.\n",
    "\n",
    "Currently I am using the `dayofweek`, `hour`, and `hourofweek` features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class Timestamp2DatetimeIndex(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Timestamp2DatetimeIndex\n",
    "    ~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    \n",
    "    This consumes a timestamp series and applies `pandas.DatetimeIndex`\n",
    "    to return a DatetimeIndex object\n",
    "    \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return pd.DatetimeIndex(X)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of Timestamp2DatetimeIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2015-06-02 20:16:08+00:00', '2015-06-02 20:31:44+00:00',\n",
       "               '2015-06-02 20:39:37+00:00', '2015-06-02 20:46:14+00:00',\n",
       "               '2015-06-02 21:07:13+00:00', '2015-06-02 21:22:06+00:00',\n",
       "               '2015-06-02 21:34:17+00:00', '2015-06-02 21:48:26+00:00',\n",
       "               '2015-06-02 23:33:23+00:00', '2015-06-02 23:37:05+00:00', \n",
       "               ...\n",
       "               '2015-06-29 20:14:54+00:00', '2015-06-29 20:24:24+00:00',\n",
       "               '2015-06-29 20:37:51+00:00', '2015-06-29 20:52:28+00:00',\n",
       "               '2015-06-29 21:05:21+00:00', '2015-06-29 21:10:59+00:00',\n",
       "               '2015-06-29 21:11:55+00:00', '2015-06-29 21:21:59+00:00',\n",
       "               '2015-06-13 21:50:17+00:00', '2015-06-11 03:49:52+00:00'],\n",
       "              dtype='datetime64[ns]', length=3165, freq=None, tz='UTC')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Timestamp2DatetimeIndex().fit_transform(X.created_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DatetimeIndexAttr\n",
    "\n",
    "Once something is a DatetimeIndex we need to access the relevant attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "class DatetimeIndexAttr(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    DatetimeIndexAttr\n",
    "    ~~~~~~~~~~~~~~~~~\n",
    "    \n",
    "    Accesses all of the available `pandas.DatetimeIndex` attributes when initialized.\n",
    "    Also provides a new attribute called \"hourofweek\".\n",
    "    \n",
    "    Usage:\n",
    "        Initialize it with kind=`attribute` that you want, for example `hour` or `dayofweek`\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, kind):\n",
    "        self.kind = kind\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        n = len(X)\n",
    "        if self.kind == \"hourofweek\":\n",
    "            col = X.dayofweek * 24 + X.hour\n",
    "        else:\n",
    "            col = getattr(X, self.kind)\n",
    "        return pd.DataFrame(col)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of DatetimeIndexAttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0  20\n",
       "1  20\n",
       "2  20\n",
       "3  20\n",
       "4  21"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pipeline([\n",
    "        (\"to_index\", Timestamp2DatetimeIndex()),\n",
    "        (\"to_hour\", DatetimeIndexAttr(\"hour\"))\n",
    "    ]).fit_transform(X.created_at).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is going to be one hot encoded, am I ashamed? A little..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "time_pipe = list()\n",
    "\n",
    "time_pipe.append(\n",
    "    (\"get_created_at\", \n",
    "     ItemGetter(\"created_at\")\n",
    "    )\n",
    ")\n",
    "\n",
    "time_pipe.append(\n",
    "    (\"to_datetimeindex\",\n",
    "    Timestamp2DatetimeIndex()\n",
    "    )\n",
    ")\n",
    "\n",
    "time_pipe.append(\n",
    "    (\"features\",\n",
    "    FeatureUnion([\n",
    "        (\"dayofweek\", \n",
    "         Pipeline(\n",
    "                    [(\"index\", DatetimeIndexAttr(\"dayofweek\")),\n",
    "                     (\"onehot\", OneHotEncoder())])),\n",
    "        (\"hour\", \n",
    "         Pipeline(\n",
    "                    [(\"index\", DatetimeIndexAttr(\"hour\")),\n",
    "                     (\"onehot\", OneHotEncoder())])),\n",
    "        (\"hourofweek\", \n",
    "         Pipeline(\n",
    "                    [(\"index\", DatetimeIndexAttr(\"hourofweek\")),\n",
    "                     (\"onehot\", OneHotEncoder())]))\n",
    "        ])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future Work\n",
    "\n",
    "Notice that right now the things are all `OneHotEncoder()`. This will change later. We see that a lot of this infromation is periodic so we can probably include features like the different between Phases rather than the time itself.\n",
    "\n",
    "This will probably function better than collapsing it into larger semantic intervals like `Afternoon` or `Sunday Afternoon`\n",
    "\n",
    "Moreover instead of using prior densities based on our other data, we could also have that a part of the fit process..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class UserEgoVectorizer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, log=True, mean=True):\n",
    "        self.log = log\n",
    "        self.mean = mean\n",
    "        \n",
    "        self.features = [\n",
    "            'user.favourites_count',\n",
    "            'user.followers_count', \n",
    "            'user.friends_count', \n",
    "            'user.statuses_count',\n",
    "            'user.verified'\n",
    "        ]\n",
    "\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        U = X[self.features].copy()\n",
    "        U[\"user.normality\"] = U[\"user.friends_count\"] \\\n",
    "                    / ((U[\"user.followers_count\"] + U[\"user.friends_count\"]) + 1)\n",
    "        \n",
    "        # all features omitting user.verified\n",
    "        for feature in self.features[:-1]:\n",
    "            # Adding one fixes the log(0) problem\n",
    "            U[feature] = np.log(U[feature]+1)\n",
    "            \n",
    "        if self.mean:\n",
    "            for feature in self.features[:-1]:\n",
    "                U[feature+\"_mean\"] = U[feature] - np.mean(U[feature])\n",
    "                U[feature+\"_std\"] = (U[feature] - np.mean(U[feature]))**2\n",
    "        return U\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of UserEgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user.favourites_count</th>\n",
       "      <th>user.followers_count</th>\n",
       "      <th>user.friends_count</th>\n",
       "      <th>user.statuses_count</th>\n",
       "      <th>user.verified</th>\n",
       "      <th>user.normality</th>\n",
       "      <th>user.favourites_count_mean</th>\n",
       "      <th>user.favourites_count_std</th>\n",
       "      <th>user.followers_count_mean</th>\n",
       "      <th>user.followers_count_std</th>\n",
       "      <th>user.friends_count_mean</th>\n",
       "      <th>user.friends_count_std</th>\n",
       "      <th>user.statuses_count_mean</th>\n",
       "      <th>user.statuses_count_std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>556e0ee3d6dfbb462880f0a5</th>\n",
       "      <td>5.978886</td>\n",
       "      <td>6.011267</td>\n",
       "      <td>7.599902</td>\n",
       "      <td>6.714171</td>\n",
       "      <td>False</td>\n",
       "      <td>0.830353</td>\n",
       "      <td>-1.490446</td>\n",
       "      <td>2.221428</td>\n",
       "      <td>-0.023291</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>1.696399</td>\n",
       "      <td>2.877768</td>\n",
       "      <td>-2.237507</td>\n",
       "      <td>5.006437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556e128ad6dfbb46288111e4</th>\n",
       "      <td>6.693324</td>\n",
       "      <td>6.914731</td>\n",
       "      <td>6.867974</td>\n",
       "      <td>9.253687</td>\n",
       "      <td>False</td>\n",
       "      <td>0.488053</td>\n",
       "      <td>-0.776008</td>\n",
       "      <td>0.602188</td>\n",
       "      <td>0.880172</td>\n",
       "      <td>0.774703</td>\n",
       "      <td>0.964471</td>\n",
       "      <td>0.930204</td>\n",
       "      <td>0.302010</td>\n",
       "      <td>0.091210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556e1464d6dfbb4628812330</th>\n",
       "      <td>6.758095</td>\n",
       "      <td>6.556778</td>\n",
       "      <td>6.529419</td>\n",
       "      <td>11.402820</td>\n",
       "      <td>False</td>\n",
       "      <td>0.492795</td>\n",
       "      <td>-0.711237</td>\n",
       "      <td>0.505858</td>\n",
       "      <td>0.522220</td>\n",
       "      <td>0.272714</td>\n",
       "      <td>0.625916</td>\n",
       "      <td>0.391770</td>\n",
       "      <td>2.451143</td>\n",
       "      <td>6.008102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          user.favourites_count  user.followers_count  \\\n",
       "_id                                                                     \n",
       "556e0ee3d6dfbb462880f0a5               5.978886              6.011267   \n",
       "556e128ad6dfbb46288111e4               6.693324              6.914731   \n",
       "556e1464d6dfbb4628812330               6.758095              6.556778   \n",
       "\n",
       "                          user.friends_count  user.statuses_count  \\\n",
       "_id                                                                 \n",
       "556e0ee3d6dfbb462880f0a5            7.599902             6.714171   \n",
       "556e128ad6dfbb46288111e4            6.867974             9.253687   \n",
       "556e1464d6dfbb4628812330            6.529419            11.402820   \n",
       "\n",
       "                         user.verified  user.normality  \\\n",
       "_id                                                      \n",
       "556e0ee3d6dfbb462880f0a5         False        0.830353   \n",
       "556e128ad6dfbb46288111e4         False        0.488053   \n",
       "556e1464d6dfbb4628812330         False        0.492795   \n",
       "\n",
       "                          user.favourites_count_mean  \\\n",
       "_id                                                    \n",
       "556e0ee3d6dfbb462880f0a5                   -1.490446   \n",
       "556e128ad6dfbb46288111e4                   -0.776008   \n",
       "556e1464d6dfbb4628812330                   -0.711237   \n",
       "\n",
       "                          user.favourites_count_std  \\\n",
       "_id                                                   \n",
       "556e0ee3d6dfbb462880f0a5                   2.221428   \n",
       "556e128ad6dfbb46288111e4                   0.602188   \n",
       "556e1464d6dfbb4628812330                   0.505858   \n",
       "\n",
       "                          user.followers_count_mean  user.followers_count_std  \\\n",
       "_id                                                                             \n",
       "556e0ee3d6dfbb462880f0a5                  -0.023291                  0.000542   \n",
       "556e128ad6dfbb46288111e4                   0.880172                  0.774703   \n",
       "556e1464d6dfbb4628812330                   0.522220                  0.272714   \n",
       "\n",
       "                          user.friends_count_mean  user.friends_count_std  \\\n",
       "_id                                                                         \n",
       "556e0ee3d6dfbb462880f0a5                 1.696399                2.877768   \n",
       "556e128ad6dfbb46288111e4                 0.964471                0.930204   \n",
       "556e1464d6dfbb4628812330                 0.625916                0.391770   \n",
       "\n",
       "                          user.statuses_count_mean  user.statuses_count_std  \n",
       "_id                                                                          \n",
       "556e0ee3d6dfbb462880f0a5                 -2.237507                 5.006437  \n",
       "556e128ad6dfbb46288111e4                  0.302010                 0.091210  \n",
       "556e1464d6dfbb4628812330                  2.451143                 6.008102  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploder = ExplodingRecordJoiner(\n",
    "    labels=[\n",
    "        \"alcohol\"\n",
    "    ],\n",
    "    user=[\n",
    "        'created_at', \n",
    "        'favourites_count', \n",
    "        'followers_count', \n",
    "        'friends_count', \n",
    "        'statuses_count',\n",
    "        'verified'\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "Pipeline([\n",
    "    (\"exploder\", exploder),\n",
    "    (\"user\", UserEgoVectorizer())    \n",
    "]).fit_transform(X).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class UserAgeMonths(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    UserAgeMonths\n",
    "    ~~~~~~~~~~~~~\n",
    "    \n",
    "    Calculates difference in months between user creation time and tweet creation\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.to_index = Timestamp2DatetimeIndex()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        tweet_time = pd.to_datetime(X[\"created_at\"])\n",
    "        user_time = pd.to_datetime(X[\"user.created_at\"])\n",
    "        return (tweet_time - user_time).apply(int) // 2.62974e15\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UserAge Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_id\n",
       "556e0ee3d6dfbb462880f0a5    11\n",
       "556e128ad6dfbb46288111e4    79\n",
       "556e1464d6dfbb4628812330    38\n",
       "dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploder = ExplodingRecordJoiner(\n",
    "    labels=[\n",
    "        \"alcohol\"\n",
    "    ],\n",
    "    user=[\n",
    "        'created_at', \n",
    "        'favourites_count', \n",
    "        'followers_count', \n",
    "        'friends_count', \n",
    "        'statuses_count',\n",
    "        'verified'\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "Pipeline([\n",
    "    (\"exploder\", exploder),\n",
    "    (\"user_months\", UserAgeMonths())    \n",
    "]).fit_transform(X).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End\n",
    "\n",
    "So now the next notebook will contain all the imported tools and provide a view of how the pipelines work together."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
